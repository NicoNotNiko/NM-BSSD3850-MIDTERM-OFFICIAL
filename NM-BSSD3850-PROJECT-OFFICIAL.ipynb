{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "thousand-familiar",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from ipywidgets import widgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "common-staff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating variables for the max length of names and labels. We have 2 labels: m or f.\n",
    "maxlen = 20\n",
    "labels = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "assured-juice",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of             name  gender\n",
       "0           name  gender\n",
       "1          james       m\n",
       "2           john       m\n",
       "3         robert       m\n",
       "4        michael       m\n",
       "...          ...     ...\n",
       "9995  martavious       m\n",
       "9996      vander       m\n",
       "9997     krystel       f\n",
       "9998  nicollette       f\n",
       "9999       elson       m\n",
       "\n",
       "[10000 rows x 2 columns]>"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load in data\n",
    "#create column names\n",
    "#convert all text to lowercase for simplicity\n",
    "df = pd.read_csv('name_gender_dataset.csv', header=None, names=['name', 'gender', 'count', 'probability']).apply(lambda x: x.astype(str).str.lower())\n",
    "#possibly redundant code\n",
    "df.columns = ['name', 'gender', 'count', 'probability']\n",
    "\n",
    "#delete 'count' and 'probability' columns as they are no use to us\n",
    "del df['count']\n",
    "del df['probability']\n",
    "\n",
    "#create variables for name and gender columns\n",
    "names = df['name']\n",
    "gender = df['gender']\n",
    "\n",
    "#removes all non-letter values. This allows us to create a useful dictionary\n",
    "token = tf.keras.preprocessing.text.Tokenizer(\n",
    "    filters='!\"#$%&()*+,./:;<=>?@[\\\\]^_`{|}~\\t\\n',\n",
    "    lower=True)\n",
    "token.fit_on_texts(df['name'])\n",
    "token.get_config()\n",
    "\n",
    "df.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "conservative-number",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Male : 4037\n",
      "Female : 5962\n"
     ]
    }
   ],
   "source": [
    "#showing the rate of males to females\n",
    "print(\"Male : \" + str(sum(gender=='m')))\n",
    "print(\"Female : \" + str(sum(gender=='f')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "therapeutic-scanner",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29\n",
      "{'o', 'r', 'f', 'z', 'END', 'b', 't', 'x', 'w', ' ', 'g', 'u', 'k', 'c', 'h', 'q', 'm', 'e', '-', 'y', 'a', 's', 'i', 'd', 'n', 'p', 'l', 'j', 'v'}\n"
     ]
    }
   ],
   "source": [
    "#possible redundant code\n",
    "names = df['name']\n",
    "gender = df['gender']\n",
    "\n",
    "#creates a list of all letters used in the dataframe\n",
    "vocab = set(' '.join([str(i) for i in names]))\n",
    "vocab.add('END')\n",
    "\n",
    "len_vocab = len(vocab)\n",
    "print(len_vocab)\n",
    "print(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "shared-generator",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'o': 0,\n",
       " 'r': 1,\n",
       " 'f': 2,\n",
       " 'z': 3,\n",
       " 'END': 4,\n",
       " 'b': 5,\n",
       " 't': 6,\n",
       " 'x': 7,\n",
       " 'w': 8,\n",
       " ' ': 9,\n",
       " 'g': 10,\n",
       " 'u': 11,\n",
       " 'k': 12,\n",
       " 'c': 13,\n",
       " 'h': 14,\n",
       " 'q': 15,\n",
       " 'm': 16,\n",
       " 'e': 17,\n",
       " '-': 18,\n",
       " 'y': 19,\n",
       " 'a': 20,\n",
       " 's': 21,\n",
       " 'i': 22,\n",
       " 'd': 23,\n",
       " 'n': 24,\n",
       " 'p': 25,\n",
       " 'l': 26,\n",
       " 'j': 27,\n",
       " 'v': 28}"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creates our dictionary using the 'vocab' list we created above\n",
    "char_index = dict((c, i) for i, c in enumerate(vocab))\n",
    "char_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "square-occasion",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creates our train and test data by randomly splitting the data. Train data must be no larger than 80% of the dataset\n",
    "msk = np.random.rand(len(df)) < 0.8\n",
    "train = (df[msk])\n",
    "test = (df[~msk])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "lesbian-dividend",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creates array of length len_vocab. \n",
    "#This array is full of zeros except for a one placed in the corresponding position for each letter in our dictionary.\n",
    "def set_flag(i):\n",
    "    tmp = np.zeros(29);\n",
    "    tmp[i] = 1\n",
    "    return(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "internal-delay",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = []\n",
    "Y_train = []\n",
    "\n",
    "#This converts our train data into the format shown above. \n",
    "#Each letter will be represented by an array\n",
    "for i in train.name:\n",
    "    tmp = [set_flag(char_index[j]) for j in str(i)]\n",
    "    for k in range(0,maxlen - len(str(i))):\n",
    "        tmp.append(set_flag(char_index[\"END\"]))\n",
    "    X_train.append(tmp)\n",
    "for i in train.gender:\n",
    "    if i == 'm':\n",
    "        Y_train.append([1,0])\n",
    "    else:\n",
    "        Y_train.append([0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "private-export",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])]\n"
     ]
    }
   ],
   "source": [
    "print(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "supreme-advancement",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8043, 20, 29)"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.asarray(X_train).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "nominated-pathology",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8043, 2)"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.asarray(Y_train).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "reduced-bridge",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create our model\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.LSTM(512, return_sequences=True, input_shape=(maxlen,len_vocab)),\n",
    "    tf.keras.layers.Dropout(0.1),\n",
    "    tf.keras.layers.LSTM(512, return_sequences=False),\n",
    "    tf.keras.layers.Dropout(0.1),\n",
    "    tf.keras.layers.Dense(2, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "color-intake",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = []\n",
    "Y_test = []\n",
    "\n",
    "#Converts our test data into the correct format/vector space\n",
    "#Same thing we did to training data\n",
    "for i in test.name:\n",
    "    tmp = [set_flag(char_index[j]) for j in str(i)]\n",
    "    for k in range(0,maxlen - len(str(i))):\n",
    "        tmp.append(set_flag(char_index[\"END\"]))\n",
    "    X_test.append(tmp)\n",
    "for i in test.gender:\n",
    "    if i == 'm':\n",
    "        Y_test.append([1,0])\n",
    "    else:\n",
    "        Y_test.append([0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "interested-pride",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1957, 20, 29)\n",
      "(1957, 2)\n"
     ]
    }
   ],
   "source": [
    "print(np.asarray(X_test).shape)\n",
    "print(np.asarray(Y_test).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "flying-violin",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(X_train)\n",
    "Y_train = np.array(Y_train)\n",
    "X_test = np.array(X_test)\n",
    "Y_test = np.array(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "worst-survey",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compile\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "devoted-bicycle",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "9/9 [==============================] - 56s 6s/step - loss: 0.4062 - accuracy: 0.8228\n",
      "Epoch 2/10\n",
      "9/9 [==============================] - 50s 5s/step - loss: 0.3960 - accuracy: 0.8237\n",
      "Epoch 3/10\n",
      "9/9 [==============================] - 51s 5s/step - loss: 0.3949 - accuracy: 0.8246\n",
      "Epoch 4/10\n",
      "9/9 [==============================] - 52s 6s/step - loss: 0.3897 - accuracy: 0.8258\n",
      "Epoch 5/10\n",
      "9/9 [==============================] - 52s 6s/step - loss: 0.3870 - accuracy: 0.8304\n",
      "Epoch 6/10\n",
      "9/9 [==============================] - 51s 6s/step - loss: 0.3927 - accuracy: 0.8274\n",
      "Epoch 7/10\n",
      "9/9 [==============================] - 52s 6s/step - loss: 0.3836 - accuracy: 0.8305\n",
      "Epoch 8/10\n",
      "9/9 [==============================] - 56s 6s/step - loss: 0.3828 - accuracy: 0.8312\n",
      "Epoch 9/10\n",
      "9/9 [==============================] - 50s 5s/step - loss: 0.3861 - accuracy: 0.8317\n",
      "Epoch 10/10\n",
      "9/9 [==============================] - 50s 5s/step - loss: 0.3844 - accuracy: 0.8305\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f9ab7316250>"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fit\n",
    "model.fit(X_train, Y_train, batch_size=1000, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "functional-biodiversity",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2678ef45cedf45b2bee9eec01c83d94d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Label(value='Enter a Name')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82aae4e845cc4a4481ad2d74832a7f5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86d680eebefe47368e8b55f65150b030",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Predict', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "label_1 = widgets.Label('Enter a Name')\n",
    "display(label_1)\n",
    "text_1 = widgets.Text()\n",
    "display(text_1)\n",
    "test_name = []\n",
    "test_name1 = []\n",
    "\n",
    "\n",
    "button = widgets.Button(description=\"Predict\")\n",
    "display(button)\n",
    "\n",
    "def predict(a):\n",
    "    x = str(text_1.value)\n",
    "    test_name.append(x)\n",
    "    \n",
    "    for i in test_name:\n",
    "        tmp = [set_flag(char_index[j]) for j in str(i)]\n",
    "        for k in range(0,maxlen - len(str(i))):\n",
    "            tmp.append(set_flag(char_index[\"END\"]))\n",
    "        test_name1.append(tmp)\n",
    "    pred = model.predict(np.asarray(test_name1))\n",
    "    print(pred)\n",
    "    print(test_name)\n",
    "\n",
    "button.on_click(predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "isolated-sequence",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "beginning-passenger",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reduced-direction",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "curious-operations",
   "metadata": {},
   "source": [
    "name=[\"roger\",\"lesley\",\"jennifer\", \"nico\", \"kathy\"]\n",
    "X=[]\n",
    "for i in name:\n",
    "    tmp = [set_flag(char_index[j]) for j in str(i)]\n",
    "    for k in range(0,maxlen - len(str(i))):\n",
    "        tmp.append(set_flag(char_index[\"END\"]))\n",
    "    X.append(tmp)\n",
    "pred=model.predict(np.asarray(X))\n",
    "pred\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
